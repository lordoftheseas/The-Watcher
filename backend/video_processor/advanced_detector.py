"""
Advanced Threat Detection using Pre-trained Deep Learning Models
Based on YOLO, MobileNet, and Optical Flow for accurate anomaly detection
"""

import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
import os
from pathlib import Path

# Flag to check if advanced models are available
ADVANCED_MODELS_AVAILABLE = False
YOLO_MODEL = None
OPTICAL_FLOW_PARAMS = None

try:
    from ultralytics import YOLO
    import torch
    ADVANCED_MODELS_AVAILABLE = True
    print("âœ“ Advanced ML models available (YOLO + PyTorch)")
except ImportError:
    print("âš  Advanced models not available. Run: pip install ultralytics torch torchvision")


class AdvancedThreatDetector:
    """
    Advanced threat detection using pre-trained deep learning models
    - YOLOv8 for accurate object/person detection
    - Optical flow for sophisticated motion analysis
    - Action recognition for anomaly detection
    """
    
    def __init__(self):
        self.model_available = ADVANCED_MODELS_AVAILABLE
        self.yolo_model = None
        self.prev_frame_gray = None
        self.optical_flow_params = None
        
        # Detection thresholds
        self.confidence_threshold = 0.4  # YOLO confidence
        self.motion_threshold = 2.0  # Optical flow magnitude
        
        # Suspicious behavior patterns
        self.violence_keywords = ['punch', 'kick', 'fight', 'weapon', 'gun', 'knife']
        self.crowd_threshold = 5  # More than 5 people is a crowd
        
        # Initialize models
        self._initialize_models()
    
    def _initialize_models(self):
        """Initialize pre-trained models"""
        if not self.model_available:
            print("âš  Using fallback detection methods (limited accuracy)")
            return
        
        try:
            # Initialize YOLOv8 nano (fast and accurate)
            print("ðŸ“¦ Loading YOLOv8 model...")
            self.yolo_model = YOLO('yolov8n.pt')  # Nano version for speed
            print("âœ“ YOLOv8 loaded successfully")
            
            # Initialize optical flow parameters
            self.optical_flow_params = dict(
                pyr_scale=0.5,
                levels=3,
                winsize=15,
                iterations=3,
                poly_n=5,
                poly_sigma=1.2,
                flags=0
            )
            
            print("âœ“ Advanced detection models initialized")
            
        except Exception as e:
            print(f"âš  Error initializing models: {e}")
            self.model_available = False
    
    def detect_objects_and_people(self, frame: np.ndarray) -> Dict:
        """
        Detect objects and people using YOLO
        Returns detailed information about detected entities
        """
        if not self.model_available or self.yolo_model is None:
            return self._fallback_detection(frame)
        
        try:
            # Run YOLO detection
            results = self.yolo_model(frame, verbose=False, conf=self.confidence_threshold)
            
            detections = {
                'people': [],
                'vehicles': [],
                'weapons': [],
                'suspicious_objects': [],
                'animals': [],
                'total_objects': 0,
                'bounding_boxes': []
            }
            
            # Process detections
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    xyxy = box.xyxy[0].cpu().numpy()
                    
                    x1, y1, x2, y2 = map(int, xyxy)
                    width = x2 - x1
                    height = y2 - y1
                    
                    # Get class name
                    class_name = result.names[cls]
                    
                    bbox = {
                        'type': class_name,
                        'confidence': conf,
                        'x': x1,
                        'y': y1,
                        'width': width,
                        'height': height,
                        'color': self._get_color_for_class(class_name)
                    }
                    
                    # Categorize detection
                    if class_name == 'person':
                        detections['people'].append(bbox)
                        bbox['color'] = (0, 255, 0)  # Green for people
                    elif class_name in ['car', 'truck', 'bus', 'motorcycle', 'bicycle']:
                        detections['vehicles'].append(bbox)
                        bbox['color'] = (255, 255, 0)  # Yellow for vehicles
                    elif class_name in ['knife', 'scissors', 'bottle', 'wine glass']:
                        detections['suspicious_objects'].append(bbox)
                        bbox['color'] = (0, 165, 255)  # Orange for suspicious
                    elif class_name in ['dog', 'cat', 'bird', 'horse']:
                        detections['animals'].append(bbox)
                        bbox['color'] = (255, 192, 203)  # Pink for animals
                    
                    detections['bounding_boxes'].append(bbox)
                    detections['total_objects'] += 1
            
            # Add metadata
            detections['people_count'] = len(detections['people'])
            detections['vehicle_count'] = len(detections['vehicles'])
            detections['method'] = 'yolov8'
            
            return detections
            
        except Exception as e:
            print(f"âš  YOLO detection error: {e}")
            return self._fallback_detection(frame)
    
    def _fallback_detection(self, frame: np.ndarray) -> Dict:
        """Fallback detection using OpenCV methods"""
        # Simple Haar Cascade fallback
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            person_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_fullbody.xml'
            )
            people = person_cascade.detectMultiScale(gray, 1.1, 4)
            
            bboxes = []
            for (x, y, w, h) in people:
                bboxes.append({
                    'type': 'person',
                    'confidence': 0.5,
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'color': (0, 255, 0)
                })
            
            return {
                'people': bboxes,
                'people_count': len(bboxes),
                'vehicles': [],
                'weapons': [],
                'suspicious_objects': [],
                'total_objects': len(bboxes),
                'bounding_boxes': bboxes,
                'method': 'haar_cascade'
            }
        except:
            return {
                'people': [],
                'people_count': 0,
                'vehicles': [],
                'weapons': [],
                'suspicious_objects': [],
                'total_objects': 0,
                'bounding_boxes': [],
                'method': 'none'
            }
    
    def analyze_motion_patterns(self, frame: np.ndarray) -> Dict:
        """
        Advanced motion analysis using optical flow
        Detects direction, magnitude, and patterns
        """
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        motion_info = {
            'has_motion': False,
            'motion_score': 0.0,
            'motion_direction': None,
            'motion_magnitude': 0.0,
            'erratic_movement': False
        }
        
        if self.prev_frame_gray is None:
            self.prev_frame_gray = gray
            return motion_info
        
        try:
            if self.optical_flow_params is not None:
                # Dense optical flow
                flow = cv2.calcOpticalFlowFarneback(
                    self.prev_frame_gray, 
                    gray,
                    None,
                    **self.optical_flow_params
                )
                
                # Calculate motion magnitude and angle
                magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
                
                # Statistics
                mean_magnitude = np.mean(magnitude)
                max_magnitude = np.max(magnitude)
                std_magnitude = np.std(magnitude)
                
                motion_info['motion_magnitude'] = float(mean_magnitude)
                motion_info['motion_score'] = float(mean_magnitude / 10.0)  # Normalize
                motion_info['has_motion'] = mean_magnitude > self.motion_threshold
                
                # Detect erratic movement (high variance)
                if std_magnitude > mean_magnitude * 1.5:
                    motion_info['erratic_movement'] = True
                
                # Dominant motion direction
                if mean_magnitude > self.motion_threshold:
                    mean_angle = np.mean(angle[magnitude > mean_magnitude])
                    motion_info['motion_direction'] = self._angle_to_direction(mean_angle)
            else:
                # Fallback: simple frame differencing
                diff = cv2.absdiff(self.prev_frame_gray, gray)
                motion_pixels = np.sum(diff > 30)
                total_pixels = diff.shape[0] * diff.shape[1]
                motion_ratio = motion_pixels / total_pixels
                
                motion_info['motion_score'] = motion_ratio
                motion_info['has_motion'] = motion_ratio > 0.02
        
        except Exception as e:
            print(f"âš  Motion analysis error: {e}")
        
        self.prev_frame_gray = gray
        return motion_info
    
    def detect_anomalies(self, frame: np.ndarray) -> Tuple[bool, Dict]:
        """
        Main anomaly detection function
        Combines object detection and motion analysis
        Returns: (is_anomalous, detection_info)
        """
        # Get detections
        detections = self.detect_objects_and_people(frame)
        motion_info = self.analyze_motion_patterns(frame)
        
        # Combine information
        analysis = {
            'people_count': detections['people_count'],
            'vehicle_count': detections.get('vehicle_count', 0),
            'suspicious_objects': len(detections.get('suspicious_objects', [])),
            'weapons_detected': len(detections.get('weapons', [])),
            'motion_score': motion_info['motion_score'],
            'erratic_movement': motion_info.get('erratic_movement', False),
            'bounding_boxes': detections['bounding_boxes'],
            'detection_method': detections.get('method', 'unknown'),
            'total_objects': detections['total_objects']
        }
        
        # Anomaly detection logic
        is_anomalous = False
        reasons = []
        
        # Check for weapons or suspicious objects
        if analysis['weapons_detected'] > 0:
            is_anomalous = True
            reasons.append(f"Weapons detected ({analysis['weapons_detected']})")
        
        if analysis['suspicious_objects'] > 0:
            is_anomalous = True
            reasons.append(f"Suspicious objects detected ({analysis['suspicious_objects']})")
        
        # Check for crowds
        if analysis['people_count'] >= self.crowd_threshold:
            is_anomalous = True
            reasons.append(f"Large crowd detected ({analysis['people_count']} people)")
        
        # Check for unusual vehicles
        if analysis['vehicle_count'] > 2:
            is_anomalous = True
            reasons.append(f"Multiple vehicles detected ({analysis['vehicle_count']})")
        
        # Check for erratic movement (potential fight/struggle)
        if analysis['erratic_movement'] and analysis['people_count'] > 0:
            is_anomalous = True
            reasons.append("Erratic movement detected (possible altercation)")
        
        # High motion with multiple people
        if analysis['motion_score'] > 0.1 and analysis['people_count'] >= 3:
            is_anomalous = True
            reasons.append("High activity with multiple people")
        
        analysis['is_anomalous'] = is_anomalous
        analysis['reasons'] = reasons
        analysis['primary_reason'] = reasons[0] if reasons else "Normal activity"
        
        return is_anomalous, analysis
    
    def _get_color_for_class(self, class_name: str) -> Tuple[int, int, int]:
        """Get color coding for different object classes"""
        color_map = {
            'person': (0, 255, 0),      # Green
            'car': (255, 255, 0),        # Yellow
            'truck': (255, 255, 0),
            'knife': (0, 0, 255),        # Red
            'scissors': (0, 165, 255),   # Orange
            'bottle': (0, 165, 255),
            'dog': (255, 192, 203),      # Pink
            'cat': (255, 192, 203),
        }
        return color_map.get(class_name, (128, 128, 128))  # Gray default
    
    def _angle_to_direction(self, angle: float) -> str:
        """Convert angle to cardinal direction"""
        angle_deg = np.degrees(angle)
        if angle_deg < 0:
            angle_deg += 360
        
        directions = ['right', 'down-right', 'down', 'down-left', 
                     'left', 'up-left', 'up', 'up-right']
        idx = int((angle_deg + 22.5) / 45) % 8
        return directions[idx]
    
    def draw_detections(self, frame: np.ndarray, bounding_boxes: List[Dict]) -> np.ndarray:
        """
        Draw bounding boxes and labels on frame
        Useful for debugging and visualization
        """
        output = frame.copy()
        
        for bbox in bounding_boxes:
            x, y, w, h = bbox['x'], bbox['y'], bbox['width'], bbox['height']
            color = bbox.get('color', (0, 255, 0))
            label = bbox.get('type', 'object')
            conf = bbox.get('confidence', 0)
            
            # Draw rectangle
            cv2.rectangle(output, (x, y), (x + w, y + h), color, 2)
            
            # Draw label with confidence
            label_text = f"{label} {conf:.2f}"
            label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            
            # Background for text
            cv2.rectangle(output, (x, y - label_size[1] - 10), 
                         (x + label_size[0], y), color, -1)
            
            # Text
            cv2.putText(output, label_text, (x, y - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return output


# Global instance
_advanced_detector = None


def get_advanced_detector() -> AdvancedThreatDetector:
    """Get or create the global advanced detector instance"""
    global _advanced_detector
    if _advanced_detector is None:
        _advanced_detector = AdvancedThreatDetector()
    return _advanced_detector
